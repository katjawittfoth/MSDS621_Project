{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import the libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import stop_words\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the initial data\n",
    "lyrics_file = pd.read_csv(\"lyrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial filters to clean up the data\n",
    "lyrics_file = lyrics_file[(lyrics_file.genre != \"Not Available\") \n",
    "                          & (lyrics_file.genre != \"Other\") \n",
    "                          & lyrics_file.lyrics.notnull()\n",
    "                         & lyrics_file.song.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to tokenize the lyrics\n",
    "def words(text):\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", text)  # delete stuff but leave at least a space to avoid clumping together\n",
    "    words = nopunct.split(\" \")\n",
    "    words = [w for w in words if len(w) > 2]  # ignore a, an, to, at, be, ...\n",
    "    words = [w.lower() for w in words]\n",
    "    words = [w for w in words if w not in stop_words.ENGLISH_STOP_WORDS]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we split the data in test and train\n",
    "target_ly = lyrics_file[[\"genre\"]]\n",
    "feature_ly = lyrics_file[[\"lyrics\"]]\n",
    "\n",
    "train_data, test_data, train_target, test_target = train_test_split(feature_ly,\n",
    "                                                                    target_ly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we fit a vectorizer\n",
    "# we create the vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english',\n",
    "                       tokenizer = words)\n",
    "\n",
    "# we fit the train data\n",
    "tf_features = tfidf.fit_transform(train_data.lyrics)\n",
    "\n",
    "# and we transform the test data\n",
    "test_features = tfidf.transform(test_data.lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we fit the model\n",
    "true_k = 11\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(tf_features)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidf.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since it is unsupervised and it doesn't know what it needs to look for, it looks for the most important feature, and it seems like the most important one was language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
