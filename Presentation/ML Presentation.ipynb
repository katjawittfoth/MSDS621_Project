{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# üé∂ Predicting Lyrics\n",
    "<hr>\n",
    "<br>\n",
    "<b> Group name: <strike>AA</strike> <i>My Machine Learning Romance</i> </b> <br>\n",
    "- Fiorella Tenorio <br>\n",
    "- Katja Wittfoth <br>\n",
    "- Rebecca Reilly <br>\n",
    "- Victoria Suarez <br>\n",
    "- Viviana M√°rquez <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br>\n",
    "<img src='USF.png', style=\"width:200px;\" align=\"left\">\n",
    "Friday, December 7th, 2018. <br>\n",
    "<b> MSDS 621 </b> - Introduction to Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Goal \n",
    "<center>\n",
    "    <img src=\"are you smarter.png\">\n",
    "    <big>Predict genre based on lyrics</big><br><br>\n",
    "    ü•ä Supervised <i>vs.</i> Unspervised  <i>vs.</i> Humans ü•ä\n",
    "</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workflow Pipeline\n",
    "<center>\n",
    "    <img src=\"workflow2.png\" style=\"height:500px\">\n",
    "</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt   \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Clean data\n",
    "def clean_lyrics(text):\n",
    "    text = re.sub('\\n', ' ', text)  # removes new lines\n",
    "    text = re.sub('\\d', '', text)  # removes numbers\n",
    "    text = re.sub('\\t', '', text)  # removes tabs\n",
    "    words = text.split(\" \")\n",
    "    words = [w for w in words if len(w) > 2]  # removes a, an, to, at, be, ...\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "df = df[pd.notnull(df['lyrics'])]\n",
    "df = df[df['genre'] != 'Not Available']\n",
    "df = df[df['genre'] != 'Other']\n",
    "df['lyrics_clean'] = df.lyrics.apply(clean_lyrics)\n",
    "\n",
    "df_clean = df[(df.genre == 'Country') | (df.genre == 'Metal') |\n",
    "              (df.genre == 'Hip-Hop') | (df.genre == 'Jazz') | (df.genre == 'Electronic')]\n",
    "\n",
    "df_clean = df_clean.sample(frac=1)  # shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üìä 1. Get data and pre-process\n",
    "\n",
    "- 380,000+ lyrics  from MetroLyrics in <a href=\"https://www.kaggle.com/gyani95/380000-lyrics-from-metrolyrics\">Kaggle</a>\n",
    "\n",
    "#### üõÅ Cleaning \n",
    "- Remove: `Null` lyrics, \"Not available\" genre, punctuation, numbers, symbols, spaces, stop words.\n",
    "- Shuffle data.\n",
    "- **Genres**: Country, Metal, Hip-Hop, Jazz, Electronic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>lyrics_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80497</th>\n",
       "      <td>80497</td>\n",
       "      <td>angst-atmet-mord</td>\n",
       "      <td>2007</td>\n",
       "      <td>bethlehem</td>\n",
       "      <td>Metal</td>\n",
       "      <td>[This is a cool song, too bad it's only 3:23 a...</td>\n",
       "      <td>[This cool song, too bad it's only and instrum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104484</th>\n",
       "      <td>104484</td>\n",
       "      <td>eiskalt</td>\n",
       "      <td>2009</td>\n",
       "      <td>culcha-candela</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>T, t, tau mich auf\\nAh, ah eiskalt, eiskalt, e...</td>\n",
       "      <td>tau mich auf Ah, eiskalt, eiskalt, eiskalt, ei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185957</th>\n",
       "      <td>185957</td>\n",
       "      <td>blown-away</td>\n",
       "      <td>2006</td>\n",
       "      <td>bizzy-bone</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[Intro: Bizzy (Playalitical)]\\nWhat's goin on,...</td>\n",
       "      <td>[Intro: Bizzy (Playalitical)] What's goin on, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220728</th>\n",
       "      <td>220728</td>\n",
       "      <td>sube</td>\n",
       "      <td>2010</td>\n",
       "      <td>ana-tijoux</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>Ho! Oouuh! What?\\nEn sus marcas, apuntar las i...</td>\n",
       "      <td>Ho! Oouuh! What? sus marcas, apuntar las ideas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>742</td>\n",
       "      <td>like-mich-am-arsch</td>\n",
       "      <td>2015</td>\n",
       "      <td>deichkind</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>Danke f√É¬ºr den Kommentar, das gef√É¬§llt mir\\nLi...</td>\n",
       "      <td>Danke f√É¬ºr den Kommentar, das gef√É¬§llt mir Lik...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                song  year          artist       genre  \\\n",
       "80497    80497    angst-atmet-mord  2007       bethlehem       Metal   \n",
       "104484  104484             eiskalt  2009  culcha-candela  Electronic   \n",
       "185957  185957          blown-away  2006      bizzy-bone     Hip-Hop   \n",
       "220728  220728                sube  2010      ana-tijoux     Hip-Hop   \n",
       "742        742  like-mich-am-arsch  2015       deichkind     Hip-Hop   \n",
       "\n",
       "                                                   lyrics  \\\n",
       "80497   [This is a cool song, too bad it's only 3:23 a...   \n",
       "104484  T, t, tau mich auf\\nAh, ah eiskalt, eiskalt, e...   \n",
       "185957  [Intro: Bizzy (Playalitical)]\\nWhat's goin on,...   \n",
       "220728  Ho! Oouuh! What?\\nEn sus marcas, apuntar las i...   \n",
       "742     Danke f√É¬ºr den Kommentar, das gef√É¬§llt mir\\nLi...   \n",
       "\n",
       "                                             lyrics_clean  \n",
       "80497   [This cool song, too bad it's only and instrum...  \n",
       "104484  tau mich auf Ah, eiskalt, eiskalt, eiskalt, ei...  \n",
       "185957  [Intro: Bizzy (Playalitical)] What's goin on, ...  \n",
       "220728  Ho! Oouuh! What? sus marcas, apuntar las ideas...  \n",
       "742     Danke f√É¬ºr den Kommentar, das gef√É¬§llt mir Lik...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## üë† 2. Modeling\n",
    "\n",
    "### ‚úÇÔ∏è Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_clean, test_size=0.2)\n",
    "train_lyrics = train['lyrics']\n",
    "train_genre = train['genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ü•ä Supervised model: Multinomial Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_lyrics = train['lyrics']\n",
    "test_lyrics = test['lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Pipelines\n",
    "pipe_nb_cv = Pipeline([\n",
    "    ('cv', CountVectorizer(stop_words='english',\n",
    "                             lowercase=False,\n",
    "                             analyzer='word')),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe_nb_tf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english',\n",
    "                             lowercase=False,\n",
    "                             analyzer='word')),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe_svc_cv = Pipeline([\n",
    "    ('cv', CountVectorizer(stop_words='english',\n",
    "                             lowercase=False,\n",
    "                             analyzer='word')),\n",
    "    ('svc', LinearSVC())\n",
    "])\n",
    "\n",
    "pipe_svc_tf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english',\n",
    "                             lowercase=False,\n",
    "                             analyzer='word')),\n",
    "    ('svc', LinearSVC())\n",
    "])\n",
    "\n",
    "pipelines = [pipe_nb_cv, pipe_nb_tf, pipe_svc_cv, pipe_svc_tf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Fit pipe\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(train_lyrics, train_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-43e7108d8785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_lyrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genre'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genre'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genre'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genre'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1270\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0;32m-> 1047\u001b[0;31m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[1;32m   1048\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "methods = []\n",
    "\n",
    "for pipe in pipelines:\n",
    "    name = pipe.steps[-1][1].__class__.__name__.split('.')[-1][0:6]\n",
    "    vect = pipe.steps[0][1].__class__.__name__.split('.')[-1][0:6]\n",
    "    \n",
    "    predicted = pipe.predict(test_lyrics)\n",
    "    accuracy = accuracy_score(predicted,test['genre'])\n",
    "    precision = precision_score(predicted,test['genre'])\n",
    "    recall = recall_score(predicted, test['genre'])\n",
    "    f1 = f1_score(predicted, test['genre'])\n",
    "    conf_mat = confusion_matrix(test['genre'], predicted)\n",
    "    \n",
    "    methods.append([name,vect,accuracy,precision,recall,f1,conf_mat])\n",
    "\n",
    "methods=pd.DataFrame(methods)\n",
    "methods.columns = ['Model', 'Vectorizer', 'Accuracy', 'Precision', 'Recall', 'F1', \"Confussion_Matrix\"]\n",
    "methods[\"Strategy\"] = methods[\"Model\"]+ \" -- \" + methods[\"Vectorizer\"]\n",
    "methods.set_index([\"Strategy\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "grid_params = dict(clf__alpha = np.arange(start=0, stop = 0.25, step = 0.05))\n",
    "\n",
    "gs = GridSearchCV(estimator=pipeline,  \n",
    "                  param_grid=grid_params,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10)\n",
    "\n",
    "gs.fit(train_lyrics, train_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "gs.best_estimator_.steps[0][1]  # best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pred = gs.best_estimator_.predict(test_lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap ‚úçÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
